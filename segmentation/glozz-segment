#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Author: Eric Kow
# License: BSD3

"""
Crude EDU segmenter from unannotated stage glozz files

Quick start
-----------

"""

from   itertools import chain
from   os.path import basename, splitext
import copy
import csv
import re
import os
import os.path
import math
import sys


from nltk.tokenize import sent_tokenize

from educe import glozz
from educe import stac
import segmentation
import stac_csv

def join_segments(xs):
    return "& ".join(xs)

def turn_segments(u):
    """
    Given a unit annotation (presumably a turn), segment its corresponding
    text and output a list of segments.
    """
    # hmm, interesting that the turn number is considered part of the text
    # for the annotations
    dirty_text = entry.text_for(u)
    drop_turn_prefix = re.compile(r'^\d* : [^:]* : (.*)')
    match = drop_turn_prefix.match(dirty_text)
    if match:
        text = match.group(1)
        post_process = lambda xs: [ segmentation.shift_span(match.start(1), x) for x in xs ]
    else:
        text = dirty_text
        post_process = lambda x: x
    return post_process(segmentation.segment(text))

import argparse

arg_parser = argparse.ArgumentParser(description='Segment into EDUs.')
arg_parser.add_argument('input' , metavar='DIR')
arg_parser.add_argument('output', metavar='DIR')
arg_parser.add_argument('--csv',
                        action='store_const',
                        const=True,
                        default=False,
                        dest='csv',
                        help='output csv file (replacing text with segmentations)')
arg_parser.add_argument('--glozz',
                        action='store_const',
                        const=True,
                        default=False,
                        dest='glozz',
                        help='output glozz XML file')
arg_parser.add_argument('--no-seg',
                        action='store_const',
                        const=False,
                        default=True,
                        dest='segment',
                        help='do not do segmentation')
arg_parser.add_argument('--verbose', '-v',
                        action='count',
                        default=1)
arg_parser.add_argument('--quiet' ,  '-q',
                        action='store_const',
                        const=0,
                        dest='verbose')
args=arg_parser.parse_args()

def is_interesting(f):
   return f.stage == 'unannotated'

# dictionaries from FileId to file paths
reader       = stac.Reader(args.input)
corpus_files = reader.filter(reader.files(), is_interesting)
corpus       = reader.slurp(corpus_files, verbose=args.verbose)
docs         = frozenset([k.doc for k in corpus])


for d in docs:
    output_dir = os.path.join(args.output, d)
    try:
        os.makedirs(output_dir)
    except OSError:
        pass # no problem
    subcorpus  = reader.filter(corpus, lambda k:k.doc == d)
    for k in subcorpus:
        subdoc = k.subdoc
        entry  = subcorpus[k]
        bname  = basename(corpus_files[k][0])
        output_filename = os.path.join(output_dir, splitext(bname)[0])
        if args.csv:
            output_filename = output_filename + ".csv"
        elif args.glozz:
            output_filename = output_filename + ".aa"

        turns = [ u for u in entry.units if u.type == 'Turn' ]

        def get_segments(t):
            text     = entry.text_for(t)
            segments = [ segmentation.span_text(text,sp) for sp in turn_segments(t) ]
            return join_segments(segments)

        if args.csv:
            with open(output_filename, 'w') as ofile:
                writer = stac_csv.mk_writer(ofile)
                def mk_row(u):
                    def get_feature(f,f2):
                        v_ = u.features[f2]
                        if v_ is None:
                            v = ""
                        else:
                            v = v_.strip()
                        return (f,v)
                    copied = [ get_feature(f,f) for f in [ 'Timestamp', 'Emitter', 'Resources' ] ]
                    pairs  = copied + [ get_feature('ID','Identifier')
                                      , get_feature('Buildups','Developments')
                                      , ('Text', get_segments(u))
                                      ]
                    return dict(pairs)
                writer.writeheader()
                for t in turns:
                    writer.writerow(mk_row(t))

        elif args.glozz:
            entry2 = copy.copy(entry)
            entry2.relations = []
            entry2.units     = [ u for u in entry.units if u.type != 'Segment' ]

            # It seems like Glozz uses the creation-date metadata field to
            # identify units (symptom: units that have different ids, but
            # some date don't appear in UI).
            #
            # Also, other tools in the pipeline seem to use the convention of
            # negative numbers for fields where the notion of a creation date
            # isn't very appropriate (automatically derived annotations)
            #
            # So we take the smallest negative date (largest absolute value)
            # and subtract from there.
            #
            # For readability, we'll jump up a couple powers of 10
            creation_dates    = [ int(u.metadata['creation-date']) for u in entry.units ]
            smallest_neg_date = min(creation_dates)
            if smallest_neg_date > 0:
                smallest_neg_date = 0
            # next two power of 10
            id_base = 10 ** (int(math.log10(abs(smallest_neg_date))) + 2)

            def mk_creation_date(i):
                return str(0 - (id_base + i))

            seg_counter = 0
            for t in turns:
                def mk_segment(s,i):
                    span = glozz.GlozzSpan(*segmentation.shift_span(t.span.char_start, s))
                    features = {}
                    author   = 'stac_segmenter'
                    # Glozz seems to use creation date internally to identify
                    # units, something ms based here doesn't seem so good
                    # because not unique (too fast); using a counter instead
                    # although by rights we also need to filter out
                    # existing creation dates
                    creation_date = mk_creation_date(seg_counter)
                    metadata = { 'author'        : author
                               , 'creation-date' : creation_date
                               , 'lastModifier'  : 'n/a'
                               , 'lastModificationDate' : '0'
                               }
                    unit_id = '_'.join([author,k.doc,k.subdoc,str(i)])
                    seg  = glozz.GlozzUnit(unit_id, span, "Segment", features, metadata)
                    return seg
                spans = turn_segments(t)
                for s in spans:
                    entry2.units.append(mk_segment(s, seg_counter))
                    seg_counter = seg_counter + 1

            stac.write_annotation_file(output_filename, entry2)
        else:
            segments = [ get_segments(t) for t in turns ]
            with open(output_filename, 'w') as ofile:
                print >> ofile, "\n".join(segments)
