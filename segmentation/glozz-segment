#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Author: Eric Kow
# License: BSD3

"""
Crude EDU segmenter from unannotated stage glozz files

Quick start
-----------

"""

from   itertools import chain
from   os.path import basename, splitext
import copy
import csv
import re
import os
import os.path
import sys


from nltk.tokenize import sent_tokenize

from educe import glozz
from educe import stac
import segmentation
import stac_csv

def join_segments(xs):
    return "& ".join(xs)

import argparse

arg_parser = argparse.ArgumentParser(description='Segment into EDUs.')
arg_parser.add_argument('input' , metavar='DIR')
arg_parser.add_argument('output', metavar='DIR')
arg_parser.add_argument('--csv',
                        action='store_const',
                        const=True,
                        default=False,
                        dest='csv',
                        help='output csv file (replacing text with segmentations)')
arg_parser.add_argument('--glozz',
                        action='store_const',
                        const=True,
                        default=False,
                        dest='glozz',
                        help='output glozz XML file')
arg_parser.add_argument('--no-seg',
                        action='store_const',
                        const=False,
                        default=True,
                        dest='segment',
                        help='do not do segmentation')
arg_parser.add_argument('--verbose', '-v',
                        action='count',
                        default=1)
arg_parser.add_argument('--quiet' ,  '-q',
                        action='store_const',
                        const=0,
                        dest='verbose')
args=arg_parser.parse_args()

def is_interesting(f):
   return f.stage == 'unannotated'

# dictionaries from FileId to file paths
reader       = stac.Reader(args.input)
corpus_files = reader.filter(reader.files(), is_interesting)
corpus       = reader.slurp(corpus_files, verbose=args.verbose)
docs         = frozenset([k.doc for k in corpus])


for d in docs:
    output_dir = os.path.join(args.output, d)
    try:
        os.makedirs(output_dir)
    except OSError:
        pass # no problem
    subcorpus  = reader.filter(corpus, lambda k:k.doc == d)
    for k in subcorpus:
        subdoc = k.subdoc
        entry  = subcorpus[k]
        bname  = basename(corpus_files[k][0])
        output_filename = os.path.join(output_dir, splitext(bname)[0])
        if args.csv:
            output_filename = output_filename + ".csv"
        elif args.glozz:
            output_filename = output_filename + ".aa"

        turns = [ u for u in entry.units if u.type == 'Turn' ]

        def get_segments(t):
            text     = entry.text_for(t)
            spans    = segmentation.segment_turn(text)
            segments = [ segmentation.span_text(text,sp) for sp in spans ]
            return join_segments(segments)

        if args.csv:
            with open(output_filename, 'w') as ofile:
                writer = stac_csv.mk_writer(ofile)
                def mk_row(u):
                    def get_feature(f,f2):
                        v_ = u.features[f2]
                        if v_ is None:
                            v = ""
                        else:
                            v = v_.strip()
                        return (f,v)
                    copied = [ get_feature(f,f) for f in [ 'Timestamp', 'Emitter', 'Resources' ] ]
                    pairs  = copied + [ get_feature('ID','Identifier')
                                      , get_feature('Buildups','Developments')
                                      , ('Text', get_segments(u))
                                      ]
                    return dict(pairs)
                writer.writeheader()
                for t in turns:
                    writer.writerow(mk_row(t))

        elif args.glozz:
            entry2 = copy.copy(entry)
            entry2.relations = []
            entry2.units     = [ u for u in entry.units if u.type != 'Segment' ]
            partial_units    = []

            for t in turns:
                def mk_segment(s):
                    span     = glozz.GlozzSpan(*segmentation.shift_span(t.span.char_start, s))
                    features = {}
                    return stac.PartialUnit(span, "Segment", features)
                spans = segmentation.segment_turn(entry.text_for(t))
                for s in spans:
                    partial_units.append(mk_segment(s))

            new_units = stac.create_units(k, entry, 'stac_segmenter', partial_units)
            entry2.units.extend(new_units)
            stac.write_annotation_file(output_filename, entry2)
        else:
            segments = [ get_segments(t) for t in turns ]
            with open(output_filename, 'w') as ofile:
                print >> ofile, "\n".join(segments)
