#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Author: Eric Kow
# License: BSD3

"""
STAC Swiss-Army knife modeled on the Glozz equivalent
"""

import argparse
from   collections import defaultdict
import copy
import itertools
import math
import os
import sys
import tempfile
import textwrap
from   cStringIO import StringIO

import educe.util
from educe import glozz, stac
from educe.annotation import Unit, Relation, Schema, Span
from educe.stac import stac_output_settings, stac_unannotated_output_settings

# ---------------------------------------------------------------------
# very generic utilities
# ---------------------------------------------------------------------

def concat(xs):
    """
    Flatten a list of lists into a list.
    """
    return list(itertools.chain.from_iterable(xs))

# ---------------------------------------------------------------------
# stac utilities
# ---------------------------------------------------------------------

def get_output_dir(args):
    if args.output:
        if os.path.isfile(args.output):
            print >> sys.stderr, "Sorry, %s already exists and is not a directory" % args.output
            sys.exit(1)
        elif not os.path.isdir(args.output):
            os.makedirs(args.output)
        return args.output
    elif args.overwrite_input:
        return args.corpus
    else:
        return tempfile.mkdtemp()

def output_path_stub(odir, k):
    # directory and basename, needs extension
    relpath        = stac.id_to_path(k)
    ofile_dirname  = os.path.join(odir, os.path.dirname(relpath))
    ofile_basename = os.path.basename(relpath)
    return os.path.join(ofile_dirname, ofile_basename)

def mk_parent_dirs(f):
    dirname = os.path.dirname(f)
    if not os.path.exists(dirname):
        os.makedirs(dirname)

def save_document(output_dir, k, doc):
    stub = output_path_stub(output_dir, k)
    mk_parent_dirs(stub)
    doc_bytes = doc.text().encode('utf-8')
    is_unannotated = k.stage == 'unannotated'

    # .aa file
    settings = stac_unannotated_output_settings\
            if is_unannotated else stac_output_settings
    out_doc          = copy.copy(doc)
    out_doc.hashcode = glozz.hashcode(StringIO(doc_bytes))
    glozz.write_annotation_file(stub + ".aa", out_doc, settings=settings)

    # .ac file
    if is_unannotated:
        with open(stub + ".ac", 'wb') as f:
            f.write(doc_bytes)

def anno_author(x):
    return x.metadata['author']

def anno_date(x):
    return int(x.metadata['creation-date'])

def set_anno_date(a,d):
    a.metadata['creation-date'] = str(d)

# ---------------------------------------------------------------------
# annotate
# ---------------------------------------------------------------------

default_inserts =\
        { 'Turn'   : ('\n', '')
        , 'Dialogue' : ('\n', '')
        , 'Segment': ('[', ']')
        }

def rough_type(anno):
    """
    Simplify STAC annotation types
    """
    if anno.type == 'Segment' or stac.is_edu(anno):
        return 'Segment'
    else:
        return anno.type

def sorted_first_widest(xs):
    """
    Given a list of nodes, return the nodes ordered by their starting point,
    and in case of a tie their inverse width (ie. widest first).
    """
    def from_span(sp):
        # negate the endpoint so that if we have a tie on the starting
        # point, the widest span comes first
        return (sp.char_start, 0 - sp.char_end)
    return sorted(xs, key=lambda x:from_span(x.text_span()))

def annotate(txt, annotations, inserts=default_inserts):
    """
    Decorate a text with arbitrary bracket symbols, as a visual
    guide to the annotations on that text. For example, in a
    chat corpus, you might use newlines to indicate turn
    boundaries and square brackets for segments.

    FIXME: this needs to become a standard educe utility,
    maybe as part of the educe.annotation layer?
    """
    def is_visible(x):
        return rough_type(x) in inserts
    if not annotations:
        return txt

    def add_endpoints(endpoints, buf, i):
        endpoints2 = []
        buf2 = buf
        for i2,rparen in endpoints:
            if i == i2:
                buf2 = buf2 + rparen
            else:
                endpoints2.append((i2,rparen))
        return endpoints2, buf2

    s_annos    = sorted_first_widest(filter(is_visible, annotations))
    endpoints  = []
    buf        = ""
    for i in range(0,len(txt)):
        c = txt[i]
        endpoints, buf = add_endpoints(endpoints, buf, i)
        while s_annos:
            nxt = s_annos[0]
            sp  = nxt.text_span()
            if sp.char_start == i:
                lparen, rparen = inserts[rough_type(nxt)]
                buf = buf + lparen
                endpoints.insert(0,(sp.char_end,rparen)) # lifo
                del s_annos[0]
            else:
                break
        buf = buf + c

    _, buf = add_endpoints(endpoints, buf, len(txt))
    return buf

# ---------------------------------------------------------------------
# portion adjustment
# ---------------------------------------------------------------------

def is_portion(anno):
    return anno.type == 'portion'

def is_portion_adjustment(anno):
    return anno.type in [ 'portion', 'merge' ]

def appends_to_last(portion):
    return portion.text_span.char_start == 0

def evil_set_text(doc, text):
    """
    This is a bit evil as it's using undocumented functionality
    from the educe.annotation.Document object
    """
    doc._text = text

def evil_set_id(anno, new_id):
    """
    This is a bit evil as it's using undocumented functionality
    from the educe.annotation.Standoff object
    """
    anno._anno_id = new_id

def shift_annotations(doc, offset):
    """
    Return a deep copy of a document such that all annotations
    have been shifted by an offset.

    If shifting right, we pad the document with whitespace
    to act as filler. If shifting left, we cut the text
    """
    def shift(x):
        if offset != 0 and isinstance(x, Unit):
            x2      = copy.deepcopy(x)
            x2.span = x.span.shift(offset)
            return x2
        else:
            return copy.deepcopy(x)

    if offset > 0:
        padding = " " * offset
        txt2    = padding + doc.text()
    else:
        start   = 0-offset
        txt2    = doc.text()[start:]
    doc2           = copy.copy(doc)
    evil_set_text(doc2, txt2)
    doc2.units     = map(shift, doc.units)
    doc2.schemas   = map(shift, doc.schemas)
    doc2.relations = map(shift, doc.relations)
    return doc2

def narrow_to_span(doc, span):
    """
    Return a deep copy of a document with only the text and
    annotations that are within the span specified by portion.
    """
    offset = 0 - span.char_start
    def slice(xs):
        return [ copy.copy(x) for x in xs if span.encloses(x.text_span()) ]
    doc2           = copy.copy(doc)
    doc2.units     = slice(doc.units)
    doc2.schemas   = slice(doc.schemas)
    doc2.relations = slice(doc.relations)
    doc2           = shift_annotations(doc2, offset)
    evil_set_text(doc2, doc.text()[span.char_start:span.char_end])
    return doc2

def compute_renames(avoid, incoming):
    """
    Given two sets of documents, return a dictionary which would
    allow us to rename ids in `incoming` so that they do not
    overlap with those in `avoid`.

    :rtype `author -> date -> date`
    """
    dates   = defaultdict(list)
    renames = defaultdict(dict)
    for doc1 in avoid.values():
        for a in doc1.annotations():
            author  = anno_author(a)
            date    = anno_date(a)
            dates[author].append(date)
    min_dates = { k:min(v) for k,v in dates.items() }
    max_dates = { k:max(v) for k,v in dates.items() }
    for doc2 in incoming.values():
        for a in doc2.annotations():
            author   = anno_author(a)
            old_date = anno_date(a)
            if author in dates and old_date in dates[author] and\
               not (author in renames and old_date in renames[author]):
                if old_date < 0:
                    new_date = min_dates[author] - 1
                    min_dates[author] = new_date
                else:
                    new_date = max_dates[author] + 1
                    max_dates[author] = new_date
                dates[author].append(new_date)
                renames[author][old_date] = new_date
    return renames

def rename_ids(renames, doc):
    """
    Return a deep copy of a document, with ids reassigned
    according to the renames dictionary
    """
    doc2 = copy.deepcopy(doc)
    for a in doc2.annotations():
        author  = anno_author(a)
        date    = anno_date(a)
        if author in renames and date in renames[author]:
            new_date = renames[author][date]
            set_anno_date(a, new_date)
            evil_set_id(a, '%s_%s' % (author, new_date))
    return doc2

def move_portion(renames, src_doc, tgt_doc, span):
    """
    Return a copy of the documents such that the span has been moved
    from source to target
    """
    tgt_txt    = tgt_doc.text()
    snipped    = narrow_to_span(src_doc, span)
    if snipped.text()[0]  == ' ' and tgt_doc.text()[-1] == ' ':
        tgt_txt = tgt_txt[:-1]
    tgt_offset = len(tgt_txt)
    snipped    = shift_annotations(snipped, tgt_offset)
    snipped    = rename_ids(renames, snipped)

    src_txt    = snipped.text()[tgt_offset:]

    new_tgt_doc           = copy.deepcopy(tgt_doc)
    new_tgt_doc.units     = new_tgt_doc.units     + snipped.units
    new_tgt_doc.relations = new_tgt_doc.relations + snipped.relations
    new_tgt_doc.schemas   = new_tgt_doc.schemas   + snipped.schemas

    if span.char_start == 0:
        # tgt_doc is on the left
        evil_set_text(new_tgt_doc, tgt_txt + src_txt)
        leftover_span = Span(span.char_end,len(src_doc.text()))
        new_src_doc   = narrow_to_span(src_doc, leftover_span)
        return new_src_doc, new_tgt_doc
    else:
        raise Exception('Merged portion must either be at beginning: %s' % span)

# ---------------------------------------------------------------------
# COMMAND move
# ---------------------------------------------------------------------

def is_source(k):
    return k.doc == args.doc and k.subdoc == args.source

def is_target(k):
    return k.doc == args.doc and k.subdoc == args.target

def reflow(text, width=40):
    def wrap(t):
        xs = textwrap.wrap(t, width)
        if xs:
            return xs
        else:
            return ['']
    return concat(wrap(t) for t in text.split("\n"))

def annotate_doc(doc):
    return annotate(doc.text(), doc.annotations())

def show_diff(doc_before, doc_after):
    lines_before = reflow(annotate_doc(doc_before))
    lines_after  = reflow(annotate_doc(doc_after))
    pairs = itertools.izip_longest(lines_before, lines_after, fillvalue='')
    return "\n".join("%-40s | %-40s" % p for p in pairs)

def main_move(args):
    output_dir = get_output_dir(args)
    if args.start != 0:
        print >> sys.stderr, "Sorry, only know how to deal with start=0 at the moment"
        sys.exit(1)

    reader     = stac.Reader(args.corpus)
    src_files  = reader.filter(reader.files(), is_source)
    tgt_files  = reader.filter(reader.files(), is_target)
    src_corpus = reader.slurp(src_files)
    tgt_corpus = reader.slurp(tgt_files)

    portion    = Span(args.start, args.end)

    renames = compute_renames(tgt_corpus, src_corpus)
    for src_k in src_corpus:
        tgt_k        = copy.copy(src_k)
        tgt_k.subdoc = args.target
        if tgt_k not in tgt_corpus:
            print >> sys.stderr, "Uh-oh! we don't have %s in the corpus" % tgt_k
            sys.exit(1)
        else:
            src_doc = src_corpus[src_k]
            tgt_doc = tgt_corpus[tgt_k]
            new_src_doc, new_tgt_doc = move_portion(renames, src_doc, tgt_doc, portion)
            diffs = ["======= TO %s   ========" % tgt_k,
                     show_diff(tgt_doc, new_tgt_doc),
                     "^------ FROM %s" % src_k,
                     show_diff(src_doc, new_src_doc),
                     ""]
            print >> sys.stderr, "\n".join(diffs)
            save_document(output_dir, src_k, new_src_doc)
            save_document(output_dir, tgt_k, new_tgt_doc)

    print >> sys.stderr, "Output files written to", output_dir

# ---------------------------------------------------------------------
# COMMAND text
# ---------------------------------------------------------------------

def main_text(args):
    is_interesting = educe.util.mk_is_interesting(args)
    reader     = stac.Reader(args.corpus)
    anno_files = reader.filter(reader.files(), is_interesting)
    corpus     = reader.slurp(anno_files, verbose=True)
    for k in sorted(corpus, key=stac.id_to_path):
        doc = corpus[k]
        def anno(sp=None):
            if sp:
                units_ = [u for u in doc.units if sp.encloses(u.span)]
                units  = copy.deepcopy(units_)
                for x in units:
                    x.span = x.span.relative(sp)
            else:
                units = doc.units
            return annotate(doc.text(sp), units).strip()
        print "========== %s ============" % k
        print
        if args.edges:
            dialogues = sorted_first_widest(u for u in doc.units if u.type == 'Dialogue')
            if dialogues:
                d_first = dialogues[0]
                print anno(d_first.text_span())
                if len(dialogues) > 1:
                    d_last = dialogues[-1]
                    print "...\n"
                    print anno(d_last.text_span()).encode('utf-8')
        else:
            print anno().encode('utf-8')
        print

# ---------------------------------------------------------------------
# COMMAND rewrite
# ---------------------------------------------------------------------

def main_rewrite(args):
    is_interesting = educe.util.mk_is_interesting(args)
    output_dir     = get_output_dir(args)
    reader         = stac.Reader(args.corpus)
    anno_files     = reader.filter(reader.files(), is_interesting)
    corpus         = reader.slurp(anno_files, verbose=True)
    for k in corpus:
        save_document(output_dir, k, corpus[k])
    print >> sys.stderr, "Output files written to", output_dir

# ---------------------------------------------------------------------
# COMMAND merge dialogue
# ---------------------------------------------------------------------

def get_annotation_with_id(sought, annotations):
    candidates = [ x for x in annotations if x.local_id() == sought ]
    if len(candidates) == 1:
        return candidates[0]
    elif len(candidates) > 1:
        raise Exception('More than one annotation found with id %s' % sought)
    else:
        raise Exception('No annotations found with id %s' % sought)

def concatenate_features(annotations, f):
    """
    Concatenate the values for the given features for all the annotations.
    Ignore cases where the feature is unset
    """
    values = filter(lambda x:x, [ x.features.get(f) for x in annotations ])
    if values:
        return " ".join(values)
    else:
        return None

def main_merge_dia(args):
    if len(args.dialogues) < 2:
        print >> sys.stderr, "Must specify at least two dialogues"
        sys.exit(1)
    output_dir     = get_output_dir(args)
    is_interesting = educe.util.mk_is_interesting(args)
    reader         = stac.Reader(args.corpus)
    anno_files     = reader.filter(reader.files(), is_interesting)
    corpus         = reader.slurp(anno_files, verbose=True)
    for k in corpus:
        doc        = corpus[k]
        dialogues  = sorted([get_annotation_with_id(d, doc.units) for d in args.dialogues],
                            key=lambda x:x.text_span().char_start)
        combined      = copy.deepcopy(dialogues[0])
        combined.span =\
                Span(min(x.text_span().char_start for x in dialogues),
                     max(x.text_span().char_end   for x in dialogues))
        for f in [ 'Trades', 'Gets', 'Dice_rolling' ]:
            combined.features[f] = concatenate_features(dialogues, f)
        for d in dialogues:
            doc.units.remove(d)
        doc.units.append(combined)
        save_document(output_dir, k, doc)
    print >> sys.stderr, "Output files written to", output_dir

# ---------------------------------------------------------------------
# options
# ---------------------------------------------------------------------

arg_parser = argparse.ArgumentParser(description='STAC Swiss Army Knife')
subparsers = arg_parser.add_subparsers(help='sub-command help')

ap_rewrite = subparsers.add_parser('rewrite', help='Read and write back without changing anything else; potentially reformats XML (for version control diffs)')
ap_rewrite.add_argument('corpus', metavar='DIR')
ap_rewrite.add_argument('--output', '-o', metavar='DIR')
ap_rewrite.add_argument('--overwrite-input', action='store_true', help='Save results back to input dir')
educe.util.add_corpus_filters(ap_rewrite)
ap_rewrite.set_defaults(func=main_rewrite)

ap_move = subparsers.add_parser('move', help='Move text from one portion to another')
ap_move.add_argument('corpus', metavar='DIR')
ap_move.add_argument('doc',    metavar='DOC')
ap_move.add_argument('source', metavar='SUBDOC')
ap_move.add_argument('start',  metavar='INT', type=int)
ap_move.add_argument('end',    metavar='INT', type=int)
ap_move.add_argument('target', metavar='SUBDOC')
ap_move.add_argument('--output', '-o', metavar='DIR')
ap_move.add_argument('--overwrite-input', action='store_true', help='Save results back to input dir')
ap_move.set_defaults(func=main_move)

ap_text = subparsers.add_parser('text', help='Dump the text in documents with segment annotations')
ap_text.add_argument('corpus', metavar='DIR')
ap_text.add_argument('--edges', action='store_true', help='First/last dialogues only')
educe.util.add_corpus_filters(ap_text)
ap_text.set_defaults(func=main_text)

ap_merge_dia = subparsers.add_parser('merge-dialogue', help='Merge several dialogue level annotations into one')
ap_merge_dia.add_argument('corpus', metavar='DIR')
ap_merge_dia.add_argument('doc',    metavar='DOC')
ap_merge_dia.add_argument('subdoc', metavar='SUBDOC')
ap_merge_dia.add_argument('--dialogues',    metavar='ANNO_ID', nargs='+')
ap_merge_dia.add_argument('--output', '-o', metavar='DIR')
ap_merge_dia.add_argument('--overwrite-input', action='store_true', help='Save results back to input dir')
ap_merge_dia.set_defaults(func=main_merge_dia)

arg_parser.add_argument('--verbose', '-v',
                        action='count',
                        default=0)
args=arg_parser.parse_args()
args.func(args)
