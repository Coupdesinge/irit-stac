#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Author: Eric Kow
# License: BSD3

"""
Part-of-speech tag all the EDUs in all the documents
(this uses the unannotated portion of the corpus)
"""

import argparse
import codecs
import copy
import itertools
import os.path
import subprocess
import sys

from educe import stac, util
from educe.annotation import Span
from educe.stac import postag

# ---------------------------------------------------------------------
# args
# ---------------------------------------------------------------------

arg_parser = argparse.ArgumentParser(description='Dump EDU text' )
arg_parser.add_argument('idir', metavar='DIR',
                        help='Input directory'
                        )
arg_parser.add_argument('odir', metavar='DIR',
                        help='Output directory'
                        )
arg_parser.add_argument('--ark-tweet-nlp', metavar='FILE',
                        help='Path to ark-tweet-nlp jar file'
                       )
arg_parser.add_argument('--live',
                        action='store_const',
                        const=True,
                        help='"Live" data (not the annotated corpus)')

util.add_corpus_filters(arg_parser, fields=[ 'doc', 'subdoc' ])
args=arg_parser.parse_args()
args.stage     = 'unannotated'
args.annotator = None
is_interesting=util.mk_is_interesting(args)
taggers = [ args.ark_tweet_nlp ]

if all([t is None for t in taggers]):
    print >> sys.stderr, "At least one tagger must be specified"
    print >> sys.stderr, "See the --help option"
    sys.exit(1)

# ---------------------------------------------------------------------
# main
# ---------------------------------------------------------------------

if args.live:
    reader = stac.LiveInputReader(args.idir)
    anno_files = reader.files()
else:
    reader     = stac.Reader(args.idir)
    anno_files = reader.filter(reader.files(), is_interesting)

corpus     = reader.slurp(anno_files, verbose=True)
if args.ark_tweet_nlp:
    postag.run_tagger(corpus, args.odir, args.ark_tweet_nlp)
