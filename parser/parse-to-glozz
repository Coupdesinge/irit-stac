#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Author: Eric Kow
# License: BSD3

"""
Help visualise output of a discourse parser.  Concretely, augment unannotated
Glozz files with attachments/relations from some attelo output file,
producing a copy of each aa file in an output directory.

Note that we assume standard STAC corpus conventions for file layout.
Output files are placed in the discourse stage.

Quick start
-----------

    cd Stac
    python code/parser/parse-to-glozz\
           corpus-dir\
           attelo-output-file\
           output-dir
    stac-util graph output-dir output-dir-png
"""

# pylint: disable=invalid-name
# pylint: enable=invalid-name

from os import path as fp
import argparse

import educe.corpus
import educe.glozz
import educe.stac
import educe.stac.util.glozz as stac_glozz
import educe.stac.util.output as stac_output
from attelo.io import (load_predictions)

import stac.attelo_out as pout

# ----------------------------------------------------------------------
# options
# ----------------------------------------------------------------------


def config_argparser(psr):
    '''
    augment argparser with flags for this utility
    '''
    psr.add_argument('input', metavar='DIR',
                     help='Glozz files (corpus structure)')
    psr.add_argument('parse', metavar='FILE',
                     help='Attelo output (.csv file)')
    psr.add_argument('output', metavar='DIR',
                     help='Output directory')

# ---------------------------------------------------------------------
# main
# ---------------------------------------------------------------------


def main():
    'main loop'

    psr = argparse.ArgumentParser(description='Convert attelo output to Glozz')
    config_argparser(psr)
    args = psr.parse_args()

    predictions = load_predictions(args.parse)
    # slurp only the docs that appear in our predictions
    reader = educe.stac.Reader(args.input)
    doc_subdocs = frozenset(pout.split_id(pid)[0] for _, pid, _ in predictions)

    def is_interesting(key):
        "if a given corpus key is one we want for parse-to-glozz"
        right_doc = (key.doc, key.subdoc) in doc_subdocs
        right_stage = key.stage == 'unannotated'
        return right_doc and right_stage
    anno_files = {k: v for k, v in reader.files().items()
                  if is_interesting(k)}
    corpus = reader.slurp(anno_files, verbose=True)

    tstamp = stac_glozz.PseudoTimestamper()
    corpus2 = pout.copy_discourse_corpus(corpus,
                                         fp.basename(args.parse))
    pout.add_predictions(tstamp, corpus2, predictions)
    pout.remove_unseen_edus(corpus2, predictions)

    for key, doc in corpus2.items():
        stac_output.save_document(args.output, key, doc)

if __name__ == '__main__':
    main()
